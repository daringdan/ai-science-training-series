{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab8c5a1e-a2bf-467a-94e4-19ea6966bf18",
   "metadata": {},
   "source": [
    "# Intro to AI-driven Science on Supercomputers\n",
    "\n",
    "## Week 2 Homework\n",
    "\n",
    "#### Dan Horner (danhorner@berkeley.edu)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739196c2-54cf-40b4-9721-e10a64654c42",
   "metadata": {},
   "source": [
    "# Hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ebd55b-b273-421a-a5a3-3896c72cc857",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662a93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19878bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da412dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 784)\n",
      "(48000, 784)\n",
      "(12000, 784)\n",
      "\n",
      "MNIST data loaded: train: 60000 test: 10000\n",
      "X_train: (48000, 784)\n",
      "y_train: (48000,)\n",
      "X_val: (12000, 784)\n",
      "y_val: (12000,)\n"
     ]
    }
   ],
   "source": [
    "# repeating the data prep from the previous notebook\n",
    "(x_train_orig, y_train_orig), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train_orig = x_train_orig.astype(np.float32)\n",
    "x_test  = x_test.astype(np.float32)\n",
    "\n",
    "x_train_orig /= 255.\n",
    "x_test  /= 255.\n",
    "\n",
    "print(x_train_orig.shape)\n",
    "x_train_orig = x_train_orig.reshape(x_train_orig.shape[0], np.prod(x_train_orig[0,:,:].shape))\n",
    "x_test = x_test.reshape(x_test.shape[0], np.prod(x_test[0,:,:].shape))\n",
    "\n",
    "print(x_train_orig.shape)\n",
    "y_train_orig = y_train_orig.astype(np.int32)\n",
    "y_test  = y_test.astype(np.int32)\n",
    "\n",
    "x_train_i, x_val, y_train_i, y_val = train_test_split(x_train_orig, y_train_orig, test_size=0.2)\n",
    "print(x_train_i.shape)\n",
    "print(x_val.shape)\n",
    "\n",
    "\n",
    "print()\n",
    "print('MNIST data loaded: train:',len(x_train_orig),'test:',len(x_test))\n",
    "print('X_train:', x_train_i.shape)\n",
    "print('y_train:', y_train_i.shape)\n",
    "print('X_val:', x_val.shape)\n",
    "print('y_val:', y_val.shape)\n",
    "\n",
    "# one-hot encoding:\n",
    "nb_classes = 10\n",
    "y_train_onehot_i = tf.keras.utils.to_categorical(y_train_i, nb_classes)\n",
    "y_val_onehot = tf.keras.utils.to_categorical(y_val, nb_classes)\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302994b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we import an implementation of a two-layer neural network \n",
    "# this code is based on pieces of the first assignment from Stanford's CSE231n course, \n",
    "# hosted at https://github.com/cs231n/cs231n.github.io with the MIT license\n",
    "from fc_net import TwoLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81886e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, true_values):\n",
    "    scores = model.loss(x)\n",
    "    predictions = np.argmax(scores, axis=1)\n",
    "    N = predictions.shape[0]\n",
    "    acc = (true_values == predictions).sum() / N\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c43e3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple implementation of stochastic gradient descent\n",
    "def sgd(model, gradients, learning_rate):\n",
    "    for p, w in model.params.items():\n",
    "        dw = gradients[p]\n",
    "        new_weights = w - learning_rate * dw\n",
    "        model.params[p] = new_weights\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8316228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one training step\n",
    "def learn(model, x_train, y_train_onehot, learning_rate):\n",
    "    loss, gradients = model.loss(x_train, y_train_onehot)\n",
    "    model = sgd(model, gradients, learning_rate)\n",
    "    return loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76670661-fcf5-4f49-b0c7-df4bf8fe69fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49754891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Best!\n",
      "0.9765\n",
      "336 0.15981224951291315 0.4472879912339568 100\n",
      "\n",
      "1\n",
      "Best!\n",
      "0.98075\n",
      "506 0.02492791121867254 0.39151707425964777 100\n",
      "\n",
      "2\n",
      "0.9729166666666667\n",
      "197 0.19594247701670905 0.43102109171724956 100\n",
      "\n",
      "3\n",
      "0.9763333333333334\n",
      "520 0.163670370040972 0.1908233578663519 100\n",
      "\n",
      "4\n",
      "0.9775\n",
      "524 0.09623376293122037 0.20388447507625584 100\n",
      "\n",
      "5\n",
      "0.9719166666666667\n",
      "215 0.14881931287840053 0.0880725328553 100\n",
      "\n",
      "6\n",
      "0.9764166666666667\n",
      "773 0.10517155889936351 0.22418485154658807 100\n",
      "\n",
      "7\n",
      "0.9770833333333333\n",
      "677 0.08363017459680365 0.15082383381806985 100\n",
      "\n",
      "8\n",
      "0.9745833333333334\n",
      "822 0.16607510215879084 0.2142820315336918 100\n",
      "\n",
      "9\n",
      "0.97675\n",
      "708 0.1457563567593147 0.40348901023168365 100\n",
      "\n",
      "10\n",
      "0.97925\n",
      "968 0.1131071693642286 0.2823896597888211 100\n",
      "\n",
      "11\n",
      "0.9749166666666667\n",
      "633 0.18515181423625376 0.35585508227573714 100\n",
      "\n",
      "12\n",
      "0.9749166666666667\n",
      "308 0.07149125137338239 0.05276130328307656 100\n",
      "\n",
      "13\n",
      "Best!\n",
      "0.9819166666666667\n",
      "995 0.02527787077651309 0.44246482823913197 100\n",
      "\n",
      "14\n",
      "0.97775\n",
      "965 0.056495551028172844 0.07582244377141942 100\n",
      "\n",
      "15\n",
      "0.9770833333333333\n",
      "197 0.10944609983551583 0.42946052471988466 100\n",
      "\n",
      "16\n",
      "0.9793333333333333\n",
      "319 0.028400780928596416 0.18753544168676167 100\n",
      "\n",
      "17\n",
      "0.9736666666666667\n",
      "769 0.17028309661418325 0.20565408101464366 100\n",
      "\n",
      "18\n",
      "0.9795\n",
      "630 0.0973791327380737 0.41779750556815454 100\n",
      "\n",
      "19\n",
      "0.9750833333333333\n",
      "134 0.08647865944666246 0.25881610594296006 100\n",
      "\n",
      "20\n",
      "0.9780833333333333\n",
      "176 0.03240421544598611 0.25416443143664313 100\n",
      "\n",
      "21\n",
      "0.97475\n",
      "170 0.12565669547212532 0.28263045531139674 100\n",
      "\n",
      "22\n",
      "0.9810833333333333\n",
      "603 0.04343882992899616 0.2654122710012323 100\n",
      "\n",
      "23\n",
      "0.97675\n",
      "411 0.09930115173874193 0.12851074342061197 100\n",
      "\n",
      "24\n",
      "0.9779166666666667\n",
      "731 0.12812873791474103 0.2934130254709228 100\n",
      "\n",
      "25\n",
      "0.9768333333333333\n",
      "241 0.13652691377063245 0.1980582666500169 100\n",
      "\n",
      "26\n",
      "0.975\n",
      "402 0.13720796125330026 0.08553335906192772 100\n",
      "\n",
      "27\n",
      "0.9798333333333333\n",
      "250 0.045741401722083797 0.25345678054121934 100\n",
      "\n",
      "28\n",
      "0.9751666666666666\n",
      "160 0.17079450726153436 0.49521185804934104 100\n",
      "\n",
      "29\n",
      "0.9735833333333334\n",
      "647 0.127367572367429 0.09262379023371853 100\n",
      "\n",
      "30\n",
      "0.97475\n",
      "326 0.15378245233341084 0.18980708946826952 100\n",
      "\n",
      "31\n",
      "0.9748333333333333\n",
      "940 0.1555429684109506 0.19984527369774763 100\n",
      "\n",
      "32\n",
      "0.9745\n",
      "275 0.1566106726966603 0.20339383968354913 100\n",
      "\n",
      "33\n",
      "0.9768333333333333\n",
      "460 0.03548418950903913 0.05873857144123957 100\n",
      "\n",
      "34\n",
      "0.97525\n",
      "727 0.148735462129583 0.16421216945098113 100\n",
      "\n",
      "35\n",
      "0.9764166666666667\n",
      "538 0.11670387186961488 0.20714497040686525 100\n",
      "\n",
      "36\n",
      "0.9805\n",
      "484 0.016812669763393257 0.3239060281605246 100\n",
      "\n",
      "37\n",
      "0.974\n",
      "653 0.18968190310221789 0.2644473542870683 100\n",
      "\n",
      "38\n",
      "0.97525\n",
      "978 0.08891483748746506 0.06624093068284458 100\n",
      "\n",
      "39\n",
      "0.9750833333333333\n",
      "642 0.16550748663614132 0.1357333426749977 100\n",
      "\n",
      "40\n",
      "0.97625\n",
      "949 0.15657004463006804 0.23502560369919184 100\n",
      "\n",
      "41\n",
      "0.9745\n",
      "242 0.16449066432201684 0.29769734907923184 100\n",
      "\n",
      "42\n",
      "0.97675\n",
      "235 0.07658960898104683 0.12242826192034044 100\n",
      "\n",
      "43\n",
      "0.9796666666666667\n",
      "481 0.028982128785697274 0.13045590843509375 100\n",
      "\n",
      "44\n",
      "0.98175\n",
      "731 0.029261082287931797 0.46023661605860394 100\n",
      "\n",
      "45\n",
      "0.9789166666666667\n",
      "520 0.08621517624297442 0.25131608488040896 100\n",
      "\n",
      "46\n",
      "0.97575\n",
      "673 0.18011488876320797 0.3092990550526005 100\n",
      "\n",
      "47\n",
      "0.9815833333333334\n",
      "764 0.03554654842533389 0.3394340070338499 100\n",
      "\n",
      "48\n",
      "0.9729166666666667\n",
      "459 0.16328138760173225 0.13399567058769604 100\n",
      "\n",
      "49\n",
      "0.9795833333333334\n",
      "950 0.07563763368026506 0.40347249827522735 100\n",
      "\n",
      "50\n",
      "0.9810833333333333\n",
      "792 0.037507554671983453 0.38378476722011945 100\n",
      "\n",
      "51\n",
      "0.98125\n",
      "973 0.010276717673375887 0.2495425957068857 100\n",
      "\n",
      "52\n",
      "0.9784166666666667\n",
      "995 0.12589327031758085 0.3816452712615554 100\n",
      "\n",
      "53\n",
      "0.9761666666666666\n",
      "310 0.14097613645076826 0.19243432082336576 100\n",
      "\n",
      "54\n",
      "0.97775\n",
      "480 0.08885104160346483 0.28775256772911645 100\n",
      "\n",
      "55\n",
      "0.9791666666666666\n",
      "767 0.10820807791244863 0.4954632051297842 100\n",
      "\n",
      "56\n",
      "0.9770833333333333\n",
      "300 0.12540712227978945 0.39730146302670494 100\n",
      "\n",
      "57\n",
      "0.9754166666666667\n",
      "716 0.16509560912965593 0.26588449331107955 100\n",
      "\n",
      "58\n",
      "0.9725833333333334\n",
      "192 0.06925369062716559 0.05059904202275695 100\n",
      "\n",
      "59\n",
      "0.9816666666666667\n",
      "452 0.026833947891208777 0.39498726238147897 100\n",
      "\n",
      "60\n",
      "0.9748333333333333\n",
      "833 0.1648153729641526 0.35962079546800185 100\n",
      "\n",
      "61\n",
      "0.9759166666666667\n",
      "608 0.17039226413279532 0.19661193911245606 100\n",
      "\n",
      "62\n",
      "0.9806666666666667\n",
      "779 0.01898600343689812 0.17868548266362788 100\n",
      "\n",
      "63\n",
      "0.9736666666666667\n",
      "898 0.16445889152727422 0.09022112652426892 100\n",
      "\n",
      "64\n",
      "0.9805\n",
      "970 0.03895881373128152 0.2245186851720568 100\n",
      "\n",
      "65\n",
      "0.9814166666666667\n",
      "993 0.02330728851592578 0.23344191867384528 100\n",
      "\n",
      "66\n",
      "0.9773333333333334\n",
      "768 0.07001315000783556 0.10258164972029196 100\n",
      "\n",
      "67\n",
      "0.9768333333333333\n",
      "225 0.1516787850945034 0.4711636890431646 100\n",
      "\n",
      "68\n",
      "0.978\n",
      "864 0.1430945762931436 0.4755196413686676 100\n",
      "\n",
      "69\n",
      "0.97\n",
      "778 0.17742678237427273 0.062472250709013376 100\n",
      "\n",
      "70\n",
      "0.9750833333333333\n",
      "429 0.1729066733557409 0.4722518366276326 100\n",
      "\n",
      "71\n",
      "0.97975\n",
      "538 0.043304870837597514 0.16795321270761432 100\n",
      "\n",
      "72\n",
      "0.9773333333333334\n",
      "176 0.054064521454571114 0.14640562070395713 100\n",
      "\n",
      "73\n",
      "0.9778333333333333\n",
      "488 0.0904234263971961 0.3226541988505643 100\n",
      "\n",
      "74\n",
      "0.9745\n",
      "236 0.17683857891827573 0.4371922971625486 100\n",
      "\n",
      "75\n",
      "0.9740833333333333\n",
      "283 0.12302958589038164 0.1581902395681679 100\n",
      "\n",
      "76\n",
      "0.9801666666666666\n",
      "850 0.0636269132924773 0.30320898869786694 100\n",
      "\n",
      "77\n",
      "0.9745\n",
      "732 0.15139985561897285 0.086580737245667 100\n",
      "\n",
      "78\n",
      "0.97475\n",
      "187 0.17677127439206708 0.4977141454141803 100\n",
      "\n",
      "79\n",
      "0.9790833333333333\n",
      "431 0.11173756040984324 0.47245855354713967 100\n",
      "\n",
      "80\n",
      "0.9795\n",
      "484 0.017496266963994624 0.15915631109083142 100\n",
      "\n",
      "81\n",
      "0.9734166666666667\n",
      "272 0.1853811255309832 0.38059784170032945 100\n",
      "\n",
      "82\n",
      "0.9785833333333334\n",
      "557 0.07028998567119844 0.25316184022984545 100\n",
      "\n",
      "83\n",
      "0.9744166666666667\n",
      "205 0.13576996256228221 0.1410278867589505 100\n",
      "\n",
      "84\n",
      "0.98025\n",
      "831 0.011356941514439675 0.13938948403593343 100\n",
      "\n",
      "85\n",
      "0.9753333333333334\n",
      "563 0.14184210210541828 0.18079529682372852 100\n",
      "\n",
      "86\n",
      "0.9779166666666667\n",
      "814 0.11699552609525965 0.2180675048025637 100\n",
      "\n",
      "87\n",
      "0.9778333333333333\n",
      "889 0.10265852976549866 0.1371113235292328 100\n",
      "\n",
      "88\n",
      "0.9725\n",
      "831 0.13306425315031128 0.06711192221662221 100\n",
      "\n",
      "89\n",
      "0.97375\n",
      "803 0.19773267727629382 0.21264618329368695 100\n",
      "\n",
      "90\n",
      "0.9765\n",
      "588 0.1673756283299528 0.45529088036011195 100\n",
      "\n",
      "91\n",
      "0.9790833333333333\n",
      "997 0.11352647768599464 0.3471034505222119 100\n",
      "\n",
      "92\n",
      "0.9764166666666667\n",
      "848 0.07715977821205924 0.08001920184063069 100\n",
      "\n",
      "93\n",
      "0.9774166666666667\n",
      "628 0.09958545118568118 0.20790322068290673 100\n",
      "\n",
      "94\n",
      "0.9786666666666667\n",
      "728 0.08265083680891905 0.27141675194309633 100\n",
      "\n",
      "95\n",
      "0.9739166666666667\n",
      "676 0.19538244860216902 0.4391335687060348 100\n",
      "\n",
      "96\n",
      "0.9731666666666666\n",
      "418 0.15147937206440013 0.09445704610542915 100\n",
      "\n",
      "97\n",
      "0.9696666666666667\n",
      "445 0.19773472702698347 0.061033670856550204 100\n",
      "\n",
      "98\n",
      "0.9795833333333334\n",
      "984 0.08102728956348984 0.43204589668333376 100\n",
      "\n",
      "99\n",
      "0.9793333333333333\n",
      "361 0.0765602375852661 0.34477683087677424 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_search = 100\n",
    "num_epochs = 50\n",
    "\n",
    "hd_rng = (100, 1000)\n",
    "ws_rng = (0.01, 0.2)\n",
    "learning_rate_rng = (0.05, 0.50) \n",
    "batch_size_rng = (100, 100)#(50, 500)\n",
    "\n",
    "best_acc = 0.0\n",
    "\n",
    "for ival in range(n_search):\n",
    "    print(ival)\n",
    "    \n",
    "    hd = int(np.random.uniform(low = hd_rng[0], high = hd_rng[1]))\n",
    "    ws = np.random.uniform(low = ws_rng[0], high = ws_rng[1])\n",
    "    learning_rate = np.random.uniform(low = learning_rate_rng[0], high = learning_rate_rng[1])\n",
    "    batch_size = int(np.random.uniform(low = batch_size_rng[0], high = batch_size_rng[1]))\n",
    "    \n",
    "    x_train = x_train_i.copy()\n",
    "    y_train = y_train_i.copy()\n",
    "    y_train_onehot = y_train_onehot_i.copy()\n",
    "\n",
    "    num_features = x_train.shape[1]\n",
    "\n",
    "    num_examples = x_train.shape[0]\n",
    "    num_batches = int(num_examples / batch_size)\n",
    "\n",
    "    model = TwoLayerNet(input_dim=num_features, hidden_dim=hd, num_classes=nb_classes, weight_scale=ws)\n",
    "\n",
    "    losses = np.zeros(num_batches*num_epochs,)\n",
    "    indices = np.arange(num_examples)\n",
    "\n",
    "    i = 0\n",
    "    for epoch in range(0, num_epochs):\n",
    "        # in each epoch, we loop over all of the training examples\n",
    "        for step in range(0, num_batches):\n",
    "            # grabbing the next batch\n",
    "            offset = step * batch_size\n",
    "            batch_range = range(offset, offset+batch_size)\n",
    "            x_train_batch = x_train[batch_range, :]\n",
    "            y_train_batch = y_train_onehot[batch_range,:]\n",
    "        \n",
    "            # feed the next batch in to do one sgd step\n",
    "            loss, model = learn(model, x_train_batch, y_train_batch, learning_rate)\n",
    "            losses[i] = loss\n",
    "            i += 1\n",
    "   \n",
    "        # reshuffle the data so that we get a new set of batches\n",
    "        np.random.shuffle(indices)\n",
    "        x_train = x_train[indices,:]\n",
    "        y_train = y_train[indices] # keep this shuffled the same way for use in accuracy calculation\n",
    "        y_train_onehot = y_train_onehot[indices,:]\n",
    "    \n",
    "    acc = accuracy(model, x_val, y_val)\n",
    "    if(acc > best_acc):\n",
    "        best_acc = acc\n",
    "        best_params = (hd, ws, learning_rate, batch_size)\n",
    "        best_model = model\n",
    "        print('Best!')\n",
    "    print(accuracy(model, x_val, y_val))\n",
    "    print(hd, ws, learning_rate, batch_size)\n",
    "    print('')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bddf87e7-8584-42dd-8e77-0c8d214cf4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 0.02527787077651309, 0.44246482823913197, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a47b3ed-bf76-41e6-ad9e-c42e7a792727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4f274c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9819166666666667\n",
      "0.9824\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(best_model, x_train, y_train))\n",
    "print(accuracy(best_model, x_val, y_val))\n",
    "print(accuracy(best_model, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f87bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs, add layers, width of layers, scale factors,\n",
    "\n",
    "# Validation test train\n",
    "\n",
    "#plot acc also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccac709-afa2-4590-8878-d9a7df58ee67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452d6b58-fd1c-416b-a961-f1f252727da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 dataset classification with CNNs\n",
    "\n",
    "Author: Tanwi Mallick, adapting codes from Bethany Lusch, Prasanna Balprakash, Corey Adams, and Kyle Felker\n",
    "\n",
    "In this notebook, we'll continue the CIFAR-10 problem using the Keras API (as included in the TensorFlow library) and incorporating convolutional layers.\n",
    "\n",
    "First, the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 data set\n",
    "\n",
    "Again we'll load the cifar10 data set. CIFAR-10 dataset contains 32x32 color images from 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. If you haven't downloaded it already, it could take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "#x_train = x_train.astype(numpy.float32)\n",
    "#x_test  = x_test.astype(numpy.float32)\n",
    "\n",
    "#x_train /= 255.\n",
    "#x_test  /= 255.\n",
    "\n",
    "#y_train = y_train.astype(numpy.int32)\n",
    "#y_test  = y_test.astype(numpy.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CIFAR-10 data loaded: train: 50000 test: 10000\n",
      "X_train: (50000, 32, 32, 3)\n",
      "y_train: (50000,)\n"
     ]
    }
   ],
   "source": [
    "from image_dataset_loader import load\n",
    "(x_train, y_train), (x_test, y_test) = load('cifar10', ['train', 'test'])\n",
    "\n",
    "x_train = x_train.astype(numpy.float32)\n",
    "x_test  = x_test.astype(numpy.float32)\n",
    "\n",
    "x_train /= 255.\n",
    "x_test  /= 255.\n",
    "\n",
    "y_train = y_train.astype(numpy.int32)\n",
    "y_test  = y_test.astype(numpy.int32)\n",
    "\n",
    "print()\n",
    "print('CIFAR-10 data loaded: train:',len(x_train),'test:',len(x_test))\n",
    "print('X_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we won't flatten the images. \n",
    "\n",
    "The training data (`X_train`) is a 3rd-order tensor of size (50000, 32, 32), i.e. it consists of 50000 images of size 32x32 pixels. \n",
    "\n",
    "`y_train` is a 50000-dimensional vector containing the correct classes ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') for each training sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network (CNN)\n",
    "\n",
    "CNN is a type of deep learning model for processing data that has a grid pattern, such as images.\n",
    "\n",
    "Let's use a small model that includes convolutional layers\n",
    "\n",
    "- The Conv2D layers operate on 2D matrices so we input the digit images directly to the model.\n",
    "    - The two Conv2D layers belows learn 32 and 64 filters respectively. \n",
    "    - They are learning filters for 3x3 windows.\n",
    "- The MaxPooling2D layer reduces the spatial dimensions, that is, makes the image smaller.\n",
    "    - It downsamples by taking the maximum value in the window \n",
    "    - The pool size of (2, 2) below means the windows are 2x2. \n",
    "    - Helps in extracting important features and reduce computation\n",
    "- The Flatten layer flattens the 2D matrices into vectors, so we can then switch to Dense layers as in the MLP model.\n",
    "\n",
    "See https://keras.io/layers/convolutional/, https://keras.io/layers/pooling/ for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![conv layer](images/conv_layer.png)\n",
    "Image credit: [Jason Brownlee](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![conv layer](images/conv.png)\n",
    "Image credit: [Anh H. Reynolds](https://anhreynolds.com/blogs/cnn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/MaxpoolSample2.png\" width=\"600\" hight=\"600\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Classifier(tf.keras.models.Model):\n",
    "\n",
    "    def __init__(self, activation=tf.nn.tanh):\n",
    "        tf.keras.models.Model.__init__(self)\n",
    "\n",
    "        self.conv_1 = tf.keras.layers.Conv2D(32, [3, 3], activation='relu')\n",
    "        self.conv_2 = tf.keras.layers.Conv2D(64, [3, 3], activation='relu')\n",
    "        self.pool_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
    "        self.drop_4 = tf.keras.layers.Dropout(0.25)\n",
    "        self.dense_5 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.drop_6 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense_7 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.pool_3(x)\n",
    "        x = self.drop_4(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = self.dense_5(x)\n",
    "        x = self.drop_6(x)\n",
    "        x = self.dense_7(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a concise way to train the network, like we did in the previous notebook. We'll see a more verbose approach below that allows more performance tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_concise(_batch_size, _n_training_epochs, _lr):\n",
    "\n",
    "    cnn_model = CIFAR10Classifier()\n",
    "\n",
    "    cnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    \n",
    "    history = cnn_model.fit(x_train, y_train, batch_size=_batch_size, epochs=_n_training_epochs)\n",
    "    return history, cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.8646 - accuracy: 0.3177\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.5041 - accuracy: 0.4594\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.3701 - accuracy: 0.5118\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.2787 - accuracy: 0.5495\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.1992 - accuracy: 0.5761\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.1557 - accuracy: 0.5906\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.1198 - accuracy: 0.6051\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.0820 - accuracy: 0.6216\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.0540 - accuracy: 0.6262\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 1.0237 - accuracy: 0.6376\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.9946 - accuracy: 0.6489\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.9686 - accuracy: 0.6602\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.9498 - accuracy: 0.6638\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.9294 - accuracy: 0.6706\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.9099 - accuracy: 0.6777\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.8829 - accuracy: 0.6861\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.8727 - accuracy: 0.6878\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.8592 - accuracy: 0.6951\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.8383 - accuracy: 0.7011\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.8283 - accuracy: 0.7009\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.8104 - accuracy: 0.7107\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7934 - accuracy: 0.7177\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7861 - accuracy: 0.7158\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7675 - accuracy: 0.7239\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7566 - accuracy: 0.7259\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7477 - accuracy: 0.7289\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7286 - accuracy: 0.7353\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7254 - accuracy: 0.7357\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7123 - accuracy: 0.7408\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.7042 - accuracy: 0.7449\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.6924 - accuracy: 0.7484\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.6755 - accuracy: 0.7498\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.6680 - accuracy: 0.7548\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.6585 - accuracy: 0.7569\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.6483 - accuracy: 0.7604\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.6418 - accuracy: 0.7630\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.6393 - accuracy: 0.7632\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.6214 - accuracy: 0.7704\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.6226 - accuracy: 0.7688\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.6127 - accuracy: 0.7725\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.6038 - accuracy: 0.7763\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5893 - accuracy: 0.7796\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5888 - accuracy: 0.7821\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5816 - accuracy: 0.7815\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5778 - accuracy: 0.7838\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.5658 - accuracy: 0.7889\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5612 - accuracy: 0.7898\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5564 - accuracy: 0.7901\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5476 - accuracy: 0.7959\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5364 - accuracy: 0.7983\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5290 - accuracy: 0.7993\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5263 - accuracy: 0.8036\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5240 - accuracy: 0.8022\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5081 - accuracy: 0.8104\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5071 - accuracy: 0.8090\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.5013 - accuracy: 0.8095\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4978 - accuracy: 0.8133\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4937 - accuracy: 0.8132\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4938 - accuracy: 0.8136\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.4877 - accuracy: 0.8162\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4872 - accuracy: 0.8168\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4790 - accuracy: 0.8172\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4730 - accuracy: 0.8215\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4654 - accuracy: 0.8262\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4638 - accuracy: 0.8260\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4588 - accuracy: 0.8254\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4570 - accuracy: 0.8263\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4459 - accuracy: 0.8301\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4461 - accuracy: 0.8327\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4388 - accuracy: 0.8323\n",
      "Epoch 71/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4331 - accuracy: 0.8335\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4318 - accuracy: 0.8363\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4302 - accuracy: 0.8367\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4276 - accuracy: 0.8369\n",
      "Epoch 75/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4290 - accuracy: 0.8373\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4285 - accuracy: 0.8383\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4175 - accuracy: 0.8404\n",
      "Epoch 78/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4165 - accuracy: 0.8392\n",
      "Epoch 79/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4154 - accuracy: 0.8422\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4191 - accuracy: 0.8411\n",
      "Epoch 81/100\n",
      "98/98 [==============================] - 1s 12ms/step - loss: 0.4075 - accuracy: 0.8457\n",
      "Epoch 82/100\n",
      "98/98 [==============================] - 1s 8ms/step - loss: 0.4071 - accuracy: 0.8473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4080 - accuracy: 0.8454\n",
      "Epoch 84/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.4032 - accuracy: 0.8474\n",
      "Epoch 85/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.3986 - accuracy: 0.8471\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.3960 - accuracy: 0.8477\n",
      "Epoch 87/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.3959 - accuracy: 0.8505\n",
      "Epoch 88/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.3981 - accuracy: 0.8476\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.3935 - accuracy: 0.8504\n",
      "Epoch 90/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.3876 - accuracy: 0.8528\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.3822 - accuracy: 0.8549\n",
      "Epoch 92/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.3867 - accuracy: 0.8514\n",
      "Epoch 93/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.3770 - accuracy: 0.8567\n",
      "Epoch 94/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.3833 - accuracy: 0.8532\n",
      "Epoch 95/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.3783 - accuracy: 0.8553\n",
      "Epoch 96/100\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 0.3805 - accuracy: 0.8569\n",
      "Epoch 97/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.3712 - accuracy: 0.8568\n",
      "Epoch 98/100\n",
      "98/98 [==============================] - 1s 7ms/step - loss: 0.3717 - accuracy: 0.8586\n",
      "Epoch 99/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.3679 - accuracy: 0.8616\n",
      "Epoch 100/100\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 0.3703 - accuracy: 0.8593\n"
     ]
    }
   ],
   "source": [
    "# This took 55 seconds per epoch on my laptop\n",
    "batch_size = 512\n",
    "epochs = 100\n",
    "lr = .01\n",
    "history, cnn_model = train_network_concise(batch_size, epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for test data.  The model should be better than the non-convolutional model even if you're only patient enough for three epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['loss'])\n",
    "plt.title('loss')\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(history.epoch,history.history['accuracy'])\n",
    "plt.title('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With enough training epochs, the test accuracy should exceed 99%.\n",
    "\n",
    "You can compare your result with the state-of-the art [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html). Even more results can be found [here](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 1.0694 - accuracy: 0.7098 - 502ms/epoch - 2ms/step\n",
      "accuracy: 70.98%\n",
      "CPU times: user 674 ms, sys: 107 ms, total: 781 ms\n",
      "Wall time: 618 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_test_reshaped = numpy.expand_dims(x_test, -1)\n",
    "scores = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"%s: %.2f%%\" % (cnn_model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also again check the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (rows: true classes; columns: predicted classes):\n",
      "\n",
      "313/313 [==============================] - 1s 895us/step\n",
      "[[779  18  46  18  14   6  13   7  64  35]\n",
      " [ 26 827   8   6   1   5   6   1  24  96]\n",
      " [ 60   4 614  60  98  58  48  32  10  16]\n",
      " [ 22  15  84 527  67 148  65  35  17  20]\n",
      " [ 31   2  96  65 644  20  47  75  18   2]\n",
      " [ 14   6  63 189  52 577  21  64   9   5]\n",
      " [  8   3  61  83  43  19 757  10   8   8]\n",
      " [ 19   2  54  37  56  56   4 756   1  15]\n",
      " [ 73  38  12   6   3   7   4   4 828  25]\n",
      " [ 30  95  12  11   5   4   6  18  30 789]]\n",
      "\n",
      "Classification accuracy for each class:\n",
      "\n",
      "0: 0.7790\n",
      "1: 0.8270\n",
      "2: 0.6140\n",
      "3: 0.5270\n",
      "4: 0.6440\n",
      "5: 0.5770\n",
      "6: 0.7570\n",
      "7: 0.7560\n",
      "8: 0.8280\n",
      "9: 0.7890\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Confusion matrix (rows: true classes; columns: predicted classes):'); print()\n",
    "predictions = cnn_model.predict(x_test)\n",
    "cm=confusion_matrix(y_test, numpy.argmax(predictions, axis=1), labels=list(range(10)))\n",
    "print(cm); print()\n",
    "\n",
    "print('Classification accuracy for each class:'); print()\n",
    "for i,j in enumerate(cm.diagonal()/cm.sum(axis=1)): print(\"%d: %.4f\" % (i,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More verbose training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach explicitly handles the looping over data. It will be helpful this afternoon for diving in and optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y_true, y_pred):\n",
    "    # if labels are integers, use sparse categorical crossentropy\n",
    "    # network's final layer is softmax, so from_logtis=False\n",
    "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "    # if labels are one-hot encoded, use standard crossentropy\n",
    "\n",
    "    return scce(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, batch_data, y_true):\n",
    "    y_pred = model(batch_data)\n",
    "    loss = compute_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a function that will manage the training loop for us:\n",
    "\n",
    "def train_loop(batch_size, n_training_epochs, model, opt):\n",
    "    \n",
    "    @tf.function()\n",
    "    def train_iteration(data, y_true, model, opt):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = forward_pass(model, data, y_true)\n",
    "\n",
    "        trainable_vars = model.trainable_variables\n",
    "\n",
    "        # Apply the update to the network (one at a time):\n",
    "        grads = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        opt.apply_gradients(zip(grads, trainable_vars))\n",
    "        return loss\n",
    "\n",
    "    for i_epoch in range(n_training_epochs):\n",
    "        print(\"beginning epoch %d\" % i_epoch)\n",
    "        start = time.time()\n",
    "\n",
    "        epoch_steps = int(50000/batch_size)\n",
    "        dataset.shuffle(50000) # Shuffle the whole dataset in memory\n",
    "        batches = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "        \n",
    "        for i_batch, (batch_data, y_true) in enumerate(batches):\n",
    "            batch_data = tf.reshape(batch_data, [-1, 32, 32, 3])\n",
    "            loss = train_iteration(batch_data, y_true, model, opt)\n",
    "            \n",
    "        end = time.time()\n",
    "        print(\"took %1.1f seconds for epoch #%d\" % (end-start, i_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(_batch_size, _n_training_epochs, _lr):\n",
    "\n",
    "    mnist_model = CIFAR10Classifier()\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(_lr)\n",
    "\n",
    "    train_loop(_batch_size, _n_training_epochs, mnist_model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning epoch 0\n",
      "took 1.1 seconds for epoch #0\n",
      "beginning epoch 1\n",
      "took 0.8 seconds for epoch #1\n",
      "beginning epoch 2\n",
      "took 0.8 seconds for epoch #2\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "dataset.shuffle(50000)\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 3\n",
    "lr = .01\n",
    "train_network(batch_size, epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: improve the accuracy of this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update this notebook to ensure more accuracy. How high can it be raised? Changes like increasing the number of epochs, altering the learning weight, altering the number of neurons the hidden layer, chnaging the optimizer, etc. could be made directly in the notebook. You can also change the model specification by expanding the network's layer. The current notebook's training accuracy is roughly 58.69%, although it varies randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda/2022-07-01",
   "language": "python",
   "name": "conda-2022-07-01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
